---
title: 4. Ceph 集群优化
date: 2023-08-16 11:32:50
permalink: /pages/bc143f/
categories:
  - Ceph
tags:
  - 
author: 
  name: brook-w
  link: https://github.com/brook-w
---

## 1. 内核优化

### 1. [块设备优化](https://www.xmmup.com/linuxyouhuazhicipanyudureadahead.html)

```sh
blockdev -V
blockdev --report [设备]
blockdev [-v|-q] 命令 设备

--getsz                   获得 512-字节扇区的大小 
--setro                   设置只读 
--setrw                   设置读写 
--getro                   获得只读 
--getdiscardzeroes        获取 忽略零数据 支持状态 
--getss                   获得逻辑块(扇区)大小 
--getpbsz                 获得物理块(扇区)大小 
--getiomin                获得最小 I/O 大小 
--getioopt                获得最优 I/O 大小 
--getalignoff             获得对齐偏移字节数 
--getmaxsect              获得每次请求的最大扇区数 
--getbsz                  获得块大小 
--setbsz                  set blocksize on file descriptor opening the block device --getsize                 获得 32-bit 扇区数量(已废弃，请使用 --getsz) 
--getsize64               获得字节大小 
--setra                   设置 readahead 
--getra                   获取 readahead 
--setfra                  设置文件系统 readahead 
--getfra                  获取文件系统 readahead 
--flushbufs               刷新缓存 
--rereadpt                重新读取分区表
```

### 2. 块设备预读大小

```sh
/sbin/blockdev --getra /dev/sda
cat /sys/class/block/sda/queue/read_ahead_kb

blockdev --report
```




## 2. 网络配置

Ceph 集群中有两个网络（管理内网和外部网络）每个节点都有 4 个 10G 光口。

管理内网：
由于管理网络主要用于集群节点之间的通信、数据同步和控制命令传输，稳定性和可靠性非常重要。在这个网络上，推荐使用 "activebackup" 运行者模式。

- 冗余性：该模式提供了故障切换和冗余性，以确保在一个主接口出现故障时能够切换到备用接口，保持管理网络的连通性。
- 稳定性：管理网络的稳定性是至关重要的，因为它直接影响到集群节点之间的通信和控制。

外部网络：

外部网络通常用于与其他集群或外部系统进行通信，以及为 OpenStack 集群等提供网络连接。在这个网络上，你可以考虑使用 "loadbalance" 运行者模式。

- 带宽利用：外部网络通常需要支持大量的数据传输，负载均衡模式可以更好地利用多个 10G 光口的带宽，从而提高整体的网络性能。
- 高吞吐量："loadbalance" 模式适用于需要处理大量数据的场景，这对于外部网络非常适用。

activebackup

```
vi /etc/sysconfig/network-scripts/ifcfg-team0
DEVICE=team0
DEVICETYPE=Team
ONBOOT=yes
BOOTPROTO=none
IPADDR=<管理内网 IP>
NETMASK=<子网掩码>
GATEWAY=<网关地址>
DNS1=<首选 DNS 服务器>
DNS2=<备选 DNS 服务器>
TEAM_CONFIG='{"runner": {"name": "activebackup"}}'
```


``` 
vi /etc/sysconfig/network-scripts/ifcfg-eth{X} [X 为网卡序号]
TYPE=Ethernet
NAME=ethX
DEVICE=ethX
ONBOOT=yes
BOOTPROTO=none
MASTER=team0
SLAVE=yes
```

loadbalance

```
DEVICE=team1
DEVICETYPE=Team
ONBOOT=yes
BOOTPROTO=none
IPADDR=<外部网络 IP>
NETMASK=<子网掩码>
GATEWAY=<网关地址>
DNS1=<首选 DNS 服务器>
DNS2=<备选 DNS 服务器>
TEAM_CONFIG='{"runner": {"name": "loadbalance"}}'
```

```
vi /etc/sysconfig/network-scripts/ifcfg-eth{X} [X 为网卡序号]
TYPE=Ethernet
NAME=ethX
DEVICE=ethX
ONBOOT=yes
BOOTPROTO=none
MASTER=team1
SLAVE=yes
```

重启网络

```
sudo systemctl restart NetworkManager
```


## Rocky 9 & Centos 9

- activebackup

```
# 创建 Team 接口
sudo nmcli con add type team con-name team0 ifname team0 config '{"runner": {"name": "activebackup"}}'

# 配置 IP 地址、子网掩码、网关和 DNS
sudo nmcli con mod team0 ipv4.method manual ipv4.address <管理内网 IP>/<子网掩码> ipv4.gateway <网关地址> ipv4.dns "<首选 DNS 服务器>,<备选 DNS 服务器>"

# 添加队员接口
sudo nmcli con add type ethernet con-name eth0 ifname eth0 master team0
sudo nmcli con add type ethernet con-name eth1 ifname eth1 master team0

# 启用 Team 接口
sudo nmcli con up team0
```

- loadbalance

```
# 创建 Team 接口
sudo nmcli con add type team con-name team1 ifname team1 config '{"runner": {"name": "loadbalance"}}'

# 配置 IP 地址、子网掩码、网关和 DNS
sudo nmcli con mod team1 ipv4.method manual ipv4.address <外部网络 IP>/<子网掩码> ipv4.gateway <网关地址> ipv4.dns "<首选 DNS 服务器>,<备选 DNS 服务器>"

# 添加队员接口
sudo nmcli con add type ethernet con-name eth2 ifname eth0 master team1
sudo nmcli con add type ethernet con-name eth3 ifname eth1 master team1

# 启用 Team 接口
sudo nmcli con up team1
```

## 参数配置

### 1. 设置 all-available-devices

```
ceph orch apply osd --all-available-devices --unmanaged=true
```

## 引用

- [ceph 优化配置](https://blog.csdn.net/wjandy0211/article/details/85013497#:~:text=read_ahead%2C%20%E9%80%9A%E8%BF%87%E6%95%B0%E6%8D%AE%E9%A2%84%E8%AF%BB%E5%B9%B6%E4%B8%94%E8%AE%B0%E8%BD%BD%E5%88%B0%E9%9A%8F%E6%9C%BA%E8%AE%BF%E9%97%AE%E5%86%85%E5%AD%98%E6%96%B9%E5%BC%8F%E6%8F%90%E9%AB%98%E7%A3%81%E7%9B%98%E8%AF%BB%E6%93%8D%E4%BD%9C%EF%BC%8C%E6%9F%A5%E7%9C%8B%E9%BB%98%E8%AE%A4%E5%80%BC%20cat%20%2F%20sys%20%2Fblock%2F%20sda%20%2F,%2F%20sys%20%2Fblock%2F%20sda%20%2F%20queue%20%2Fread%20_ahead_kb)

- [Ceph 场景选择](https://blog.csdn.net/wylfengyujiancheng/article/details/88299773)