---
title: 7. Kafka源码解析
date: 2022-05-07 00:00:00
permalink: /pages/88ecf9/
categories:
  - 数据库
  - Kafka
tags:
  - 
author: 
  name: brook-w
  link: https://github.com/brook-w
---

## 1. 源码环境准备

### 1. [源码下载地址](http://kafka.apache.org/downloads)

### 2. 安装 JDK&Scala

需要在 Windows 本地安装 JDK 8 或者 JDK8 以上版本，这里推荐 [JAVA 17](https://bell-sw.com/pages/downloads/#/java-17-current)

需要在 Windows 本地安装 Scala2.12

### 3. 加载源码包

将 kafka-3.0.0-src.tgz 源码包，解压到非中文目录。例如：D:\01_software\kafka-3.0.0-src

打开 IDEA，点击 File->Open…->源码包解压的位置。

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.60locf90ib00.jpg)

### 4. 安装 gradle

IDEA 会自动安装，推荐手动安装

## 2. 生产者源码

发送流程

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.1r8ss6zd9dts.jpg)


### 1. 初始化

生产者 main 线程初始化

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.jeipxrqrq88.jpg)

生产者 sender 线程初始化

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.7bi1dxscggo0.jpg)

#### 1. 程序入口

1. 从自己编写的 main 方法开始阅读

```java
package com.atguigu.kafka.producer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Properties;
public class CustomProducer {
	public static void main(String[] args) {
		// 0 配置
		Properties properties = new Properties();
		// 连接集群 bootstrap.servers
		properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092,hadoop103:9092");
		// 指定对应的 key 和 value 的序列化类型 key.serializer
		properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, 
		StringSerializer.class.getName());
		properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,Strin
		gSerializer.class.getName());
		// 1 创建 kafka 生产者对象
		// "" hello
		KafkaProducer<String, String> kafkaProducer = new
		KafkaProducer<>(properties);
		// 2 发送数据
		for (int i = 0; i < 5; i++) {
			kafkaProducer.send(new 
			ProducerRecord<>("first","atguigu"+i));
		}
		// 3 关闭资源
		kafkaProducer.close();
	}
}
```

#### 2. 生产者 main 线程初始化

- KafkaProducer.java

```java
// KafkaProducer.java
public KafkaProducer(Properties properties) {
	this(properties, null, null);
}
public KafkaProducer(Properties properties, Serializer<K> 
keySerializer, Serializer<V> valueSerializer) {
	this(Utils.propsToMap(properties), keySerializer, 
	valueSerializer);
}
public KafkaProducer(Map<String, Object> configs, Serializer<K> 
keySerializer, Serializer<V> valueSerializer) {
	this(new 
	ProducerConfig(ProducerConfig.appendSerializerToConfig(configs, 
	keySerializer, valueSerializer)),
	keySerializer, valueSerializer, null, null, null, 
	Time.SYSTEM);
}
```

- KafkaProducer 构造方法

```java
KafkaProducer(ProducerConfig config,
 Serializer<K> keySerializer,
 Serializer<V> valueSerializer,
 ProducerMetadata metadata,
 KafkaClient kafkaClient,
 ProducerInterceptors<K, V> interceptors,
 Time time) {
	try {
		this.producerConfig = config;
		this.time = time;
		// 获取事务 id
		String transactionalId = 
		config.getString(ProducerConfig.TRANSACTIONAL_ID_CONFIG);
		// 获取客户端 id
		this.clientId = 
		config.getString(ProducerConfig.CLIENT_ID_CONFIG);
		LogContext logContext;
		if (transactionalId == null)
		logContext = new LogContext(String.format("[Producer 
clientId=%s] ", clientId)); else
		logContext = new LogContext(String.format("[Producer 
clientId=%s, transactionalId=%s] ", clientId, transactionalId));
		log = logContext.logger(KafkaProducer.class);
		log.trace("Starting the Kafka producer");
		Map<String, String> metricTags = 
		Collections.singletonMap("client-id", clientId);
		MetricConfig metricConfig = new 
		MetricConfig().samples(config.getint(ProducerConfig.METRICS_NUM_S
		AMPLES_CONFIG))
		.timeWindow(config.getlong(ProducerConfig.METRICS_SAMPLE_WINDO
		W_MS_CONFIG), TimeUnit.MILLISECONDS)
		.recordLevel(Sensor.RecordingLevel.forName(config.getString(Pr
		oducerConfig.METRICS_RECORDING_LEVEL_CONFIG)))
		.tags(metricTags);
		List<MetricsReporter> reporters = 
		config.getConfiguredInstances(ProducerConfig.METRIC_REPORTER_CLAS
		SES_CONFIG,
		MetricsReporter.class,
		Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, 
		clientId));
		// 监控相关配置
		JmxReporter jmxReporter = new JmxReporter();
		jmxReporter.configure(config.originals(Collections.singletonMa
		p(ProducerConfig.CLIENT_ID_CONFIG, clientId)));
		reporters.add(jmxReporter);
		MetricsContext metricsContext = new 
		KafkaMetricsContext(JMX_PREFIX,
		                    config.originalsWithPrefix(CommonClientConfigs.METRICS_CONTEXT
		_PREFIX));
		this.metrics = new Metrics(metricConfig, reporters, time, 
		metricsContext);
		// 分区器配置
		this.partitioner = config.getConfiguredInstance(
		ProducerConfig.PARTITIONER_CLASS_CONFIG,
		Partitioner.class,
		Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, 
		clientId));
		// 重试时间间隔参数配置，默认值 100ms
		long retryBackoffMs = 
		config.getlong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);
		// 序列化配置
		if (keySerializer == null) {
			this.keySerializer = 
			config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_
			CONFIG,
			Serializer.class);
			this.keySerializer.configure(config.originals(Collections.sing
			letonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId)), true);
		} else {
			config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);
			this.keySerializer = keySerializer;
		}
		if (valueSerializer == null) {
			this.valueSerializer = 
			config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLAS
			S_CONFIG,Serializer.class);
			this.valueSerializer.configure(config.originals(Collections.si
			ngletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId)), false);
		} else {
			config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);
			this.valueSerializer = valueSerializer;
		}
		// 拦截器配置
		List<ProducerInterceptor<K, V>> interceptorList = (List) 
		config.getConfiguredInstances(
		ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,
		ProducerInterceptor.class,
		Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, 
		clientId));
		if (interceptors != null)
		this.interceptors = interceptors; else
		this.interceptors = new 
		ProducerInterceptors<>(interceptorList);
		ClusterResourceListeners clusterResourceListeners = 
		configureClusterResourceListeners(keySerializer,
		                                  valueSerializer, interceptorList, reporters);
		// 生产者发往 Kafka 集群单条信息的最大值，默认 1m
		this.maxRequestSize = 
		config.getint(ProducerConfig.MAX_REQUEST_SIZE_CONFIG);
		// 缓存大小，默认 32m
		this.totalMemorySize = 
		config.getlong(ProducerConfig.BUFFER_MEMORY_CONFIG);
		// 压缩配置，默认 none
		this.compressionType = 
		CompressionType.forName(config.getString(ProducerConfig.COMPRESSI
		ON_TYPE_CONFIG));
		this.maxBlockTimeMs = 
		config.getlong(ProducerConfig.MAX_BLOCK_MS_CONFIG);
		int deliveryTimeoutMs = configureDeliveryTimeout(config, 
		log);
		this.apiVersions = new ApiVersions();
		this.transactionManager = configureTransactionState(config, 
		logContext);
		// 上下文环境
		// 批次大下，默认 16k
		// 是否压缩，默认 none
		// linger.ms，默认值 0。
		// 重试间隔时间，默认值 100ms。
		// delivery.timeout.ms 默认值 2 分钟。
		// request.timeout.ms 默认值 30s。
		this.accumulator = new RecordAccumulator(logContext,
		config.getint(ProducerConfig.BATCH_SIZE_CONFIG),
		this.compressionType,
		lingerMs(config),
		retryBackoffMs,
		deliveryTimeoutMs,
		metrics,
		PRODUCER_METRIC_GROUP_NAME,
		time,
		apiVersions,
		transactionManager,
		new BufferPool(this.totalMemorySize, 
		config.getint(ProducerConfig.BATCH_SIZE_CONFIG), metrics, time, 
		PRODUCER_METRIC_GROUP_NAME));
		// Kafka 集群地址
		List<InetSocketAddress> addresses = 
		ClientUtils.parseAndValidateAddresses(
		config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG),
		config.getString(ProducerConfig.CLIENT_DNS_LOOKUP_CONFIG));
		// 从 Kafka 集群获取元数据
		if (metadata != null) {
			this.metadata = metadata;
		} else {
			// metadata.max.age.ms 默认值 5 分钟。生产者每隔多久需要更新一下自己的元数据
			// metadata.max.idle.ms 默认值 5 分钟。网络最多空闲时间设置，超
			过该阈值，就关闭该网络
			this.metadata = new ProducerMetadata(retryBackoffMs,
			config.getlong(ProducerConfig.METADATA_MAX_AGE_CONFIG),
			config.getlong(ProducerConfig.METADATA_MAX_IDLE_CONFIG),
			logContext,
			clusterResourceListeners,
			Time.SYSTEM);
			this.metadata.bootstrap(addresses);
		}
		this.errors = this.metrics.sensor("errors");
		// 初始化 sender 线程
		this.sender = newSender(logContext, kafkaClient, 
		this.metadata);
		String ioThreadName = NETWORK_THREAD_PREFIX + " | " + 
		clientId;
		// 启动发送线程
		this.ioThread = new KafkaThread(ioThreadName, this.sender, 
		true);
		this.ioThread.start();
		config.logUnused();
		AppInfoParser.registerAppInfo(JMX_PREFIX, clientId, metrics, 
		time.milliseconds());
		log.debug("Kafka producer started");
	}
	catch (Throwable t) {
		... ...
	}
}
```

### 2. 发送数据到缓冲区(KafkaProducer.java)

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.2gbt9jlbxmdc.jpg)

#### 1. 发送总体流程

- 查看 send 方法

```java
for (int i = 0; i < 5; i++) {
 kafkaProducer.send(new ProducerRecord<>("first","atguigu"+i));
}
```

- KafkaProducer.java

```java
@Override
public Future<RecordMetadata> send(ProducerRecord<K, V> record) {
	return send(record, null);
}
@Override
public Future<RecordMetadata> send(ProducerRecord<K, V> record, 
Callback callback) {
	// intercept the record, which can be potentially modified; 
	this method does not throw exceptions
	// 拦截器处理发送的数据
	ProducerRecord<K, V> interceptedRecord = 
	this.interceptors.onSend(record);
	return doSend(interceptedRecord, callback);
}
```

- 点击 onSend()方法，进行拦截器相关处理

```java
public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record) {
	ProducerRecord<K, V> interceptRecord = record;
	for (ProducerInterceptor<K, V> interceptor : this.interceptors) 
	{
		try {
			// 拦截器处理
			interceptRecord = interceptor.onSend(interceptRecord);
		}
		catch (Exception e) {
			// do not propagate interceptor exception, log and 
			continue calling other interceptors
			// be careful not to throw exception from here
			if (record != null)
			log.warn("Error executing interceptor onSend 
callback for topic: {}, partition: {}", record.topic(), 
			record.partition(), e); else
			log.warn("Error executing interceptor onSend 
callback", e);
		}
	}
	return interceptRecord;
}
```

- 从拦截器处理中返回，点击 doSend()方法

```java
private Future<RecordMetadata> doSend(ProducerRecord<K, V> record,Callback callback) {
	TopicPartition tp = null;
	try {
		throwIfProducerClosed();
		// first make sure the metadata for the topic is available
		long nowMs = time.milliseconds();
		ClusterAndWaitTime clusterAndWaitTime;
		try {
			// 从 Kafka 拉取元数据。maxBlockTimeMs 表示最多能等待多长时间。
			clusterAndWaitTime = waitOnMetadata(record.topic(), 
			record.partition(), nowMs, maxBlockTimeMs);
		}
		catch (KafkaException e) {
			if (metadata.isClosed())
			throw new KafkaException("Producer closed while send in progress", e);
			throw e;
		}
		nowMs += clusterAndWaitTime.waitedOnMetadataMs;
		// 剩余时间 = 最多能等待时间 - 用了多少时间；
		long remainingWaitMs = Math.max(0, maxBlockTimeMs -
		clusterAndWaitTime.waitedOnMetadataMs);
		// 更新集群元数据
		Cluster cluster = clusterAndWaitTime.cluster;
		// 序列化操作
		byte[] serializedKey;
		try {
			serializedKey = keySerializer.serialize(record.topic(), 
			record.headers(), record.key());
		}
		catch (ClassCastException cce) {
			throw new SerializationException("Can't convert key of class " + record.key().getClass().getName() +
			" to class " + 
			producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFI
			G).getName() +
			" specified in key.serializer", cce);
		}
		byte[] serializedValue;
		try {
			serializedValue = 
			valueSerializer.serialize(record.topic(), record.headers(), 
			record.value());
		}
		catch (ClassCastException cce) {
			throw new SerializationException("Can't convert value of class " + record.value().getClass().getName() +
			" to class " + 
			producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CON
			FIG).getName() +
			" specified in value.serializer", cce);
		}
		// 分区操作（根据元数据信息）
		int partition = partition(record, serializedKey, 
		serializedValue, cluster);
		tp = new TopicPartition(record.topic(), partition);
		setReadOnly(record.headers());
		Header[] headers = record.headers().toArray();
		int serializedSize = 
		AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsab
		leProduceMagic(),
		compressionType, serializedKey, serializedValue, 
		headers);
		// 校验发送消息的大小是否超过最大值，默认是 1m
		ensureValidRecordSize(serializedSize);
		long timestamp = record.timestamp() == null ? nowMs : 
		record.timestamp();
		if (log.isTraceEnabled()) {
			log.trace("Attempting to append record {} with callback {} to topic {} partition {}", record, callback, record.topic(), 
			partition);
		}
		// 消息发送的回调函数
		// producer callback will make sure to call both 'callback' 
		and interceptor callback
		Callback interceptCallback = new 
		InterceptorCallback<>(callback, this.interceptors, tp);
		if (transactionManager != null && 
		transactionManager.isTransactional()) {
			transactionManager.failIfNotReadyForSend();
		}
		// 内存，默认 32m，里面是默认 16k 一个批次
		RecordAccumulator.RecordAppendResult result = 
		accumulator.append(tp, timestamp, serializedKey,
		serializedValue, headers, interceptCallback, 
		remainingWaitMs, true, nowMs);
		if (result.abortForNewBatch) {
			int prevPartition = partition;
			partitioner.onNewBatch(record.topic(), cluster, 
			prevPartition);
			partition = partition(record, serializedKey, 
			serializedValue, cluster);
			tp = new TopicPartition(record.topic(), partition);
			if (log.isTraceEnabled()) {
				log.trace("Retrying append due to new batch creation for topic {} partition {}. The old partition was {}", 
				record.topic(), partition, prevPartition);
			}
			// producer callback will make sure to call both 
			'callback' and interceptor callback
			interceptCallback = new InterceptorCallback<>(callback, 
			this.interceptors, tp);
			result = accumulator.append(tp, timestamp, 
			serializedKey,
			serializedValue, headers, interceptCallback, 
			remainingWaitMs, false, nowMs);
		}
		if (transactionManager != null && 
		transactionManager.isTransactional())
		transactionManager.maybeAddPartitionToTransaction(tp);
		// 批次满了 或者 创建了一个新的批次，唤醒 sender 发送线程
		if (result.batchIsFull || result.newBatchCreated) {
			log.trace("Waking up the sender since topic {} partition {} is either full or getting a new batch", 
			record.topic(), partition);
			this.sender.wakeup();
		}
		return result.future;
	}
	catch (ApiException e) {
		... ...
	}
}
```

#### 2. 分区选择

- 默认分区规则
```java
int partition = partition(record, serializedKey, serializedValue, cluster);
tp = new TopicPartition(record.topic(), partition);
private int partition(ProducerRecord<K, V> record, byte[] 
serializedKey, byte[] serializedValue, Cluster cluster) {
	// 指定了分区，那就直接用该分区号
	Integer partition = record.partition();
	return partition != null ?
	partition :
	// 分区器选择分区
	partitioner.partition(
	record.topic(), record.key(), serializedKey, 
	record.value(), serializedValue, cluster);
}
```

> 点击 partition，跳转到 **Partitioner 接口**。选中 partition，点击 ctrl+ h，查找接口实现类

```java
int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);
```

- 选择默认的分区器 **DefaultPartitioner**

```java
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster,int numPartitions) {
	// 没有指定 key：
	if (keyBytes == null) {
		return stickyPartitionCache.partition(topic, cluster);
	}
	// 指定 key:按照 key 的 hash 值对分区取模
	// hash the keyBytes to choose a partition
	return Utils.toPositive(Utils.murmur2(keyBytes)) % 
	numPartitions;
}
// 没有指定 key 和分区的处理方式
public int partition(String topic, Cluster cluster) {
	Integer part = indexCache.get(topic);
	if (part == null) {
		return nextPartition(topic, cluster, -1);
	}
	return part;
}
public int nextPartition(String topic, Cluster cluster, int 
prevPartition) {
	List<PartitionInfo> partitions = 
	cluster.partitionsForTopic(topic);
	Integer oldPart = indexCache.get(topic);
	Integer newPart = oldPart;
	// Check that the current sticky partition for the topic is 
	either not set or that the partition that 
	// triggered the new batch matches the sticky partition that 
	needs to be changed.
	if (oldPart == null || oldPart == prevPartition) {
		List<PartitionInfo> availablePartitions = 
		cluster.availablePartitionsForTopic(topic);
		if (availablePartitions.size() < 1) {
			Integer random = 
			Utils.toPositive(ThreadLocalRandom.current().nextint());
			newPart = random % partitions.size();
		} else if (availablePartitions.size() == 1) {
			newPart = availablePartitions.get(0).partition();
		} else {
			while (newPart == null || newPart.equals(oldPart)) {
				int random = 
				Utils.toPositive(ThreadLocalRandom.current().nextint());
				newPart = availablePartitions.get(random % 
				availablePartitions.size()).partition();
			}
		}
		// Only change the sticky partition if it is null or 
		prevPartition matches the current sticky partition.
		if (oldPart == null) {
			indexCache.putIfAbsent(topic, newPart);
		} else {
			indexCache.replace(topic, prevPartition, newPart);
		}
		return indexCache.get(topic);
	}
	return indexCache.get(topic);
}
```

#### 3. 发送消息大小校验(KafkaProducer.java)

> 缓存区大小

```java
ensureValidRecordSize(serializedSize);
```

```java
private void ensureValidRecordSize(int size) {
	// 一次请求获取消息的最大值，默认是 1m
	if (size > maxRequestSize)
	throw new RecordTooLargeException("The message is " + size 
	+ " bytes when serialized which is larger than " + 
	maxRequestSize + ", which is the value of the " +
	ProducerConfig.MAX_REQUEST_SIZE_CONFIG + " configuration.");
	// 缓冲区内存总大小，默认 32m
	if (size > totalMemorySize)
	throw new RecordTooLargeException("The message is " + size 
	+
	" bytes when serialized which is larger than the total memory buffer you have configured with the " +
	ProducerConfig.BUFFER_MEMORY_CONFIG +
	" configuration.");
}
```

#### 4. 内存池(KafkaProducer.java)

```java
RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptCallback, remainingWaitMs, true, nowMs);

public RecordAppendResult append(TopicPartition tp, long timestamp, byte[] key, byte[] value, Header[] headers, Callback callback, long maxTimeToBlock, boolean abortOnNewBatch, long nowMs) throws
InterruptedException
{
    // We keep track of the number of appending thread to make sure we do not miss batches in
    // abortIncompleteBatches(). appendsInProgress.incrementAndGet(); ByteBuffer buffer = null;
    if(headers == null) headers = Record.EMPTY_HEADERS;
    try
    {
        // 每个分区，创建或者获取一个队列
        // check if we have an in-progress batch Deque<ProducerBatch> dq = getOrCreateDeque(tp); synchronized (dq) {
        if(closed) throw new KafkaException("Producer closed while send in progress");
        // 尝试向队列里面添加数据（没有分配内存、批次对象，所以失败）
        RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq, nowMs);
        if(appendResult != null) return appendResult;
    }
    //	we	don't	have	an	in-progress	record	batch	try	to allocate a new batch
    if(abortOnNewBatch)
    {
        //	Return	a	result	that	will	cause	another	call	to
        append.
        return new RecordAppendResult(null, false, false, true);
    }
    byte maxUsableMagic = apiVersions.maxUsableProduceMagic();
    // 取批次大小（默认 16k）和消息大小的最大值（上限默认 1m）。这样设计的主要原因是有可能一条消息的大小大于批次大小。
    int size = Math.max(this.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));
    log.trace("Allocating a new {} byte message buffer for topic {} partition {} with remaining timeout {}ms", size, tp.topic(), tp.partition(), maxTimeToBlock);
    // 根据批次大小（默认 16k）和消息大小中最大值，分配内存
    buffer = free.allocate(size, maxTimeToBlock);
    // Update the current time in case the buffer allocation blocked above.
    nowMs = time.milliseconds();
    synchronized(dq)
    {
        //	Need	to	check	if	producer	is	closed	again	after grabbing the dequeue lock.
        if(closed) throw new KafkaException("Producer closed while send in progress");
        // 尝试向队列里面添加数据（有内存，但是没有批次对象）
        RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq, nowMs);
        if(appendResult != null)
        {
            // Somebody else found us a batch, return the one we waited for! Hopefully this doesn't happen often...
            return appendResult;
        }
        MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic);
        // 根据内存大小封装批次（有内存、有批次对象）
        ProducerBatch batch
        recordsBuilder, nowMs); = new ProducerBatch(tp,
        // 尝试向队列里面添加数据
        FutureRecordMetadata future = Objects.requireNonNull(batch.tryAppend(timestamp, key, value, headers, callback, nowMs));
        // 把新创建的批次放到队列末尾
        dq.addLast(batch); incomplete.add(batch);
        // Don't deallocate this buffer in the finally block as it's being used in the record batch
        buffer = null;
        return new RecordAppendResult(future, dq.size() > 1 || batch.isFull(), true, false);
    }
}
finally
{
    // 如果发生异常，释放内存
    if(buffer != null) free.deallocate(buffer);
    appendsInProgress.decrementAndGet();
}
```

### 3. sender 线程发送数据



![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.39bfl1ejo180.jpg)

- 1. 详解发送线程

<!-- TODO 补全代码 -->

```java
if(result.batchIsFull || result.newBatchCreated)
{
    log.trace("Waking up the sender since topic {} partition {} 
        is either full or getting a new batch ", record.topic(), 
        partition);
    this.sender.wakeup();
}
```

- 2. 进入 sender 发送线程的 run()方法 

```java
```

## 3. 消费者源码

消费者组消费流程

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.6w5cynrrifw0.jpg)

### 1. 初始化

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.2q3183dgxjc0.jpg)

#### 1. 程序入口


```java
package com.atguigu.kafka.consumer;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import java.time.Duration;
import java.util.ArrayList;
import java.util.Properties;

public class CustomConsumer {
    public static void main(String[] args) {
        // 0 配置
        Properties properties = new Properties();
        // 连接 bootstrap.servers
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102: 9092, hadoop103: 9092 ");
            // 反序列化
            properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
            // 配置消费者组 id
            properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test");
            // 手动提交
            properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
            // 1 创建一个消费者 "", "hello"
            KafkaConsumer < String, String > kafkaConsumer = new KafkaConsumer < > (properties);
            // 2 订阅主题 first
            ArrayList < String > topics = new ArrayList < > (); topics.add("first"); kafkaConsumer.subscribe(topics);
            // 3 消费数据
            while(true) {
                ConsumerRecords < String, String > consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));
                for(ConsumerRecord < String, String > consumerRecord: consumerRecords) {
                    System.out.println(consumerRecord);
                }
                // 手动提交 offset
                // kafkaConsumer.commitSync();
                kafkaConsumer.commitAsync();
            }
        }
    }
```

#### 2.  消费者初始化

- 1. 点击 main()方法中的 KafkaConsumer ()

`KafkaConsumer.java`

```java
public KafkaConsumer(Properties properties) {
    this(properties, null, null);
}
public KafkaConsumer(Properties properties, Deserializer < K > keyDeserializer, Deserializer < V > valueDeserializer) {
    this(Utils.propsToMap(properties), keyDeserializer, valueDeserializer);
}
public KafkaConsumer(Map < String, Object > configs, Deserializer < K > keyDeserializer, Deserializer < V > valueDeserializer) {
    this(new ConsumerConfig(ConsumerConfig.appendDeserializerToConfig(configs, keyDeserializer, valueDeserializer)), keyDeserializer, valueDeserializer);
}
```

- 2. 跳转到 KafkaConsumer 构造方法

```java
KafkaConsumer(ConsumerConfig config, Deserializer < K > keyDeserializer, Deserializer < V > valueDeserializer) {
        try {
            GroupRebalanceConfig groupRebalanceConfig = new
            GroupRebalanceConfig(config, GroupRebalanceConfig.ProtocolType.CONSUMER);
            // 获取消费者组 id 和客户端 id
            this.groupId = Optional.ofNullable(groupRebalanceConfig.groupId);
            this.clientId = config.getString(CommonClientConfigs.CLIENT_ID_CONFIG);
            LogContext logContext;
            // If group.instance.id is set, we will append it to the 
            log context.
            if(groupRebalanceConfig.groupInstanceId.isPresent()) {
                logContext = new LogContext("[Consumer instanceId=" + groupRebalanceConfig.groupInstanceId.get() + ", clientId=" + clientId + ", groupId=" + groupId.orElse("null") + "] ");
            } else {
                logContext = new LogContext("[Consumer clientId=" + clientId + ", groupId=" + groupId.orElse("null") + "] ");
            }
            this.log = logContext.logger(getClass());
            boolean enableAutoCommit = config.maybeOverrideEnableAutoCommit();
            groupId.ifPresent(groupIdStr - > {
                    if(groupIdStr.isEmpty()) {
                        log.warn("Support for using the empty group id by 
                            consumers is deprecated and will be removed in the next major release.
                            ");
                        }
                    }); log.debug("Initializing the Kafka consumer");
                // 等待服务端响应的最大等待时间，默认是 30s
                this.requestTimeoutMs = config.getInt(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG); this.defaultApiTimeoutMs = config.getInt(ConsumerConfig.DEFAULT_API_TIMEOUT_MS_CONFIG); this.time = Time.SYSTEM; this.metrics = buildMetrics(config, time, clientId);
                // 重试时间间隔
                this.retryBackoffMs = config.getLong(ConsumerConfig.RETRY_BACKOFF_MS_CONFIG);
                // 拦截器配置
                List < ConsumerInterceptor < K, V >> interceptorList = (List) config.getConfiguredInstances(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, ConsumerInterceptor.class, Collections.singletonMap(ConsumerConfig.CLIENT_ID_CONFIG, clientId)); this.interceptors = new ConsumerInterceptors < > (interceptorList);
                // key 和 value 反序列化配置
                if(keyDeserializer == null) {
                    this.keyDeserializer = config.getConfiguredInstance(ConsumerConfig.KEY_DESERIALIZER_CLAS S_CONFIG, Deserializer.class);
                    this.keyDeserializer.configure(config.originals(Collections.si ngletonMap(ConsumerConfig.CLIENT_ID_CONFIG, clientId)), true);
                } else {
                    config.ignore(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG);
                    this.keyDeserializer = keyDeserializer;
                }
                if(valueDeserializer == null) {
                    this.valueDeserializer = config.getConfiguredInstance(ConsumerConfig.VALUE_DESERIALIZER_CL ASS_CONFIG, Deserializer.class);
                    this.valueDeserializer.configure(config.originals(Collections.singletonMap(ConsumerConfig.CLIENT_ID_CONFIG, clientId)), false);
                } else {
                    config.ignore(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG);
                    this.valueDeserializer = valueDeserializer;
                }
                // offset 从什么位置开始消费，默认是 latest
                OffsetResetStrategy offsetResetStrategy = OffsetResetStrategy.valueOf(config.getString(ConsumerConfig.AUTO_ OFFSET_RESET_CONFIG).toUpperCase(Locale.ROOT)); this.subscriptions = new SubscriptionState(logContext, offsetResetStrategy); ClusterResourceListeners clusterResourceListeners = configureClusterResourceListeners(keyDeserializer, valueDeserializer, metrics.reporters(), interceptorList);
                // 获取元数据
                // 配置是否可以消费系统主题数据
                // 配置是否允许自动创建主题
                this.metadata = new ConsumerMetadata(retryBackoffMs, config.getLong(ConsumerConfig.METADATA_MAX_AGE_CONFIG), !config.getBoolean(ConsumerConfig.EXCLUDE_INTERNAL_TOPICS_CONF IG), config.getBoolean(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONF IG), subscriptions, logContext, clusterResourceListeners);
                // 配置连接 Kafka 集群
                List < InetSocketAddress > addresses = ClientUtils.parseAndValidateAddresses(config.getList(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG), config.getString(ConsumerConfig.CLIENT_DNS_LOOKUP_CONFIG)); this.metadata.bootstrap(addresses); String metricGrpPrefix = "consumer"; FetcherMetricsRegistry metricsRegistry = new FetcherMetricsRegistry(Collections.singleton(CLIENT_ID_METRIC_TAG), metricGrpPrefix); ChannelBuilder channelBuilder = ClientUtils.createChannelBuilder(config, time, logContext); this.isolationLevel = IsolationLevel.valueOf(config.getString(ConsumerConfig.ISOLATION_LEVEL_CONFIG).toUppe rCase(Locale.ROOT)); Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);
                // 心跳时间,默认 3s
                int heartbeatIntervalMs = config.getInt(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG); ApiVersions apiVersions = new ApiVersions(); NetworkClient netClient = new NetworkClient(new Selector(config.getLong(ConsumerConfig.CONNECTIONS_MAX_IDLE_MS_CO NFIG), metrics, time, metricGrpPrefix, channelBuilder, logContext), this.metadata, clientId, 100, config.getLong(ConsumerConfig.RECONNECT_BACKOFF_MS_CONFIG), config.getLong(ConsumerConfig.RECONNECT_BACKOFF_MAX_MS_CONFIG), config.getInt(ConsumerConfig.SEND_BUFFER_CONFIG), config.getInt(ConsumerConfig.RECEIVE_BUFFER_CONFIG), config.getInt(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG), config.getLong(ConsumerConfig.SOCKET_CONNECTION_SETUP_TIMEOUT_ MS_CONFIG), config.getLong(ConsumerConfig.SOCKET_CONNECTION_SETUP_TIMEOUT_ MAX_MS_CONFIG), time, true, apiVersions, throttleTimeSensor, logContext);
                // 创建一个消费者客户端
                this.client = new ConsumerNetworkClient(logContext, netClient, metadata, time, retryBackoffMs, config.getInt(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG), heartbeatIntervalMs); //Will avoid blocking an 
                extended period of time to prevent heartbeat thread starvation
                // 获取消费者分区分配策略
                this.assignors = ConsumerPartitionAssignor.getAssignorInstances(config.getList(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CO NFIG), config.originals(Collections.singletonMap(ConsumerConfig.CLIEN T_ID_CONFIG, clientId)));
                // 创建消费者协调器
                // 自动提交 Offset 时间间隔，默认 5s
                // no coordinator will be constructed for the default (null) 
                group id this.coordinator = !groupId.isPresent() ? null : new ConsumerCoordinator(groupRebalanceConfig, logContext, this.client, assignors, this.metadata, this.subscriptions, metrics, metricGrpPrefix, this.time, enableAutoCommit, config.getInt(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG), this.interceptors, config.getBoolean(ConsumerConfig.THROW_ON_FETCH_STABLE_OFFSET_ UNSUPPORTED));
                // 抓取数据配置
                // 一次抓取最小值，默认 1 个字节
                // 一次抓取最大值，默认 50m
                // 一次抓取最大等待时间，默认 500ms
                // 每个分区抓取的最大字节数，默认 1m
                // 一次 poll 拉取数据返回消息的最大条数，默认是 500 条。
                // key 和 value 的反序列化
                this.fetcher = new Fetcher < > (logContext, this.client, config.getInt(ConsumerConfig.FETCH_MIN_BYTES_CONFIG), config.getInt(ConsumerConfig.FETCH_MAX_BYTES_CONFIG), config.getInt(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG), config.getInt(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG), config.getInt(ConsumerConfig.MAX_POLL_RECORDS_CONFIG), config.getBoolean(ConsumerConfig.CHECK_CRCS_CONFIG), config.getString(ConsumerConfig.CLIENT_RACK_CONFIG), this.keyDeserializer, this.valueDeserializer, this.metadata, this.subscriptions, metrics, metricsRegistry, this.time, this.retryBackoffMs, this.requestTimeoutMs, isolationLevel, apiVersions); this.kafkaConsumerMetrics = new KafkaConsumerMetrics(metrics, metricGrpPrefix); config.logUnused(); AppInfoParser.registerAppInfo(JMX_PREFIX, clientId, metrics, time.milliseconds()); log.debug("Kafka consumer initialized");
            } catch(Throwable t) {
              ......
            }
        }
```

### 2. 消费者订阅主题

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.596kop1kkgg0.jpg)

- 1. 点击自己编写的 CustomConsumer.java 中的 **subscribe()**方法

```java
// 2 订阅主题 first
ArrayList<String> topics = new ArrayList<>();
topics.add("first");
kafkaConsumer.subscribe(topics);
```

`KafkaConsumer.java`

```java
@Override
public void subscribe(Collection < String > topics) {
    subscribe(topics, new NoOpConsumerRebalanceListener());
}

@Override
public void subscribe(Collection < String > topics, ConsumerRebalanceListener listener) {
        acquireAndEnsureOpen();
        try {
            maybeThrowInvalidGroupIdException();
            // 异常情况处理
            if(topics == null) throw new IllegalArgumentException("Topic collection to 
                subscribe to cannot be null ");
                if(topics.isEmpty()) {
                    // treat subscribing to empty topic list as the same as 
                    unsubscribing
                    this.unsubscribe();
                } else {
                    for(String topic: topics) {
                        if(Utils.isBlank(topic)) throw new IllegalArgumentException("Topic collection to subscribe to cannot contain null or empty topic");
                        }
                        throwIfNoAssignorsConfigured();
                        // 清空订阅异常主题的缓存数据
                        fetcher.clearBufferedDataForUnassignedTopics(topics);
                        log.info("Subscribed to topic(s): {}", Utils.join(topics, ", "));
                        // 判断是否需要更改订阅主题，如果需要更改主题，则更新元数据信息
                        if(this.subscriptions.subscribe(new HashSet < > (topics), listener)) metadata.requestUpdateForNewTopics();
                    }
                } finally {
                    release();
                }
            }
            public synchronized boolean subscribe(Set < String > topics, ConsumerRebalanceListener listener) {
                // 注册负载均衡监听（例如消费者组中，其他消费者退出触发再平衡）
                registerRebalanceListener(listener);
                // 按照设置的主题开始订阅，自动分配分区
                setSubscriptionType(SubscriptionType.AUTO_TOPICS);
                // 修改订阅主题信息
                return changeSubscription(topics);
            }
            private boolean changeSubscription(Set < String > topicsToSubscribe) {
                    // 如果订阅的主题和以前订阅的一致，就不需要修改订阅信息。如果不一致，就需
                    要修改。
                    if(subscription.equals(topicsToSubscribe)) return false;
                    subscription = topicsToSubscribe;
                    return true;
                }
                // 如果订阅的和以前不一致，需要更新元数据信息
            public synchronized int requestUpdateForNewTopics() {
                // Override the timestamp of last refresh to let immediate 
                update.
                this.lastRefreshMs = 0;
                this.needPartialUpdate = true;
                this.requestVersion++;
                return this.updateVersion;
            }
```

### 3. 消费者拉取和处理数据

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.6bnv4mscixo0.jpg)


#### 1. 消费总体流程

- 1. 点击自己编写的 CustomConsumer.java 中的 poll ()方法

```java
// 3 消费数据
while(true) {
    ConsumerRecords < String, String > consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));
    for(ConsumerRecord < String, String > consumerRecord: consumerRecords) {
        System.out.println(consumerRecord);
    }
}
```

`KafkaConsumer.java`

```java
@
Override
public ConsumerRecords < K, V > poll(final Duration timeout) {
    return poll(time.timer(timeout), true);
}
private ConsumerRecords < K, V > poll(final Timer timer, final boolean includeMetadataInTimeout) {
        acquireAndEnsureOpen();
        try {
            // 记录开始拉取消息时间
            this.kafkaConsumerMetrics.recordPollStart(timer.currentTimeMs());
            if(this.subscriptions.hasNoSubscriptionOrUserAssignment()) {
                throw new IllegalStateException("Consumer is not 
                    subscribed to any topics or assigned any partitions ");
                }
                do {
                    client.maybeTriggerWakeup();
                    if(includeMetadataInTimeout) {
                        // try to update assignment metadata BUT do not need 
                        to block on the timer
                        for join group
                        // 1、消费者 or 消费者组初始化
                        updateAssignmentMetadataIfNeeded(timer, false);
                    } else {
                        while(!updateAssignmentMetadataIfNeeded(time.timer(Long.MAX_VALUE), true)) {
                            log.warn("Still waiting for metadata");
                        }
                    }
                    // 2、开始拉取数据
                    final Map < TopicPartition, List < ConsumerRecord < K, V >>> records = pollForFetches(timer);
                    if(!records.isEmpty()) {
                        // before returning the fetched records, we can send 
                        off the next round of fetches
                        // and avoid block waiting for their responses to 
                        enable pipelining
                        while the user
                        // is handling the fetched records.
                        //
                        // NOTE: since the consumed position has already 
                        been updated, we must not allow
                        // wakeups or any other errors to be triggered prior 
                        to returning the fetched records.
                        if(fetcher.sendFetches() > 0 || client.hasPendingRequests()) {
                                client.transmitSends();
                            }
                            // 3、拦截器处理消息
                        return this.interceptors.onConsume(new ConsumerRecords < > (records));
                    }
                } while (timer.notExpired());
                return ConsumerRecords.empty();
            } finally {
                release();
                this.kafkaConsumerMetrics.recordPollEnd(timer.currentTimeMs());
            }
}
```

#### 2. 消费者/消费者组初始化


#### 3. 拉取数据


#### 4. 拦截器处理数据

- 在 poll()方法中点击 onConsume()方法

```java
// 3、拦截器处理消息
// 数据从服务器端，返回后，放入集合中缓存
final Map < TopicPartition, List < ConsumerRecord < K, V >>> records = pollForFetches(timer);
... ...
// 从集合中拉取数据处理，首先经过的是拦截器
return this.interceptors.onConsume(new ConsumerRecords < > (records));
```

```java
public ConsumerRecords < K, V > onConsume(ConsumerRecords < K, V > records) {
        ConsumerRecords < K, V > interceptRecords = records;
        for(ConsumerInterceptor < K, V > interceptor: this.interceptors) {
            try {
                interceptRecords = interceptor.onConsume(interceptRecords);
            } catch(Exception e) {
                // do not propagate interceptor exception, log and 
                continue calling other interceptors
                log.warn("Error executing interceptor onConsume 
                    callback ", e);
                }
            }
            return interceptRecords;
        }
```

### 4. 消费者 Offset 提交

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.59385z782cw0.jpg)

#### 1. 手动同步提交 Offset

`CustomConsumer.java`

```java
// 手动提交
properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
// 1 创建一个消费者 "", "hello"
KafkaConsumer < String, String > kafkaConsumer = new
KafkaConsumer < > (properties);
// 2 订阅主题 first
ArrayList < String > topics = new ArrayList < > ();
topics.add("first");
kafkaConsumer.subscribe(topics);
// 3 消费数据
while(true) {
    ConsumerRecords < String, String > consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));
    for(ConsumerRecord < String, String > consumerRecord: consumerRecords) {
        System.out.println(consumerRecord);
    }
    // 手动提交 offset
    kafkaConsumer.commitSync();
}
```

`KafkaConsumer.java`

```java

@Override
public void commitSync() {
    commitSync(Duration.ofMillis(defaultApiTimeoutMs));
}

@Override
public void commitSync(Duration timeout) {
    commitSync(subscriptions.allConsumed(), timeout);
}

@Override
public void commitSync(final Map < TopicPartition, OffsetAndMetadata > offsets, final Duration timeout) {
    acquireAndEnsureOpen();
    try {
        maybeThrowInvalidGroupIdException();
        offsets.forEach(this::updateLastSeenEpochIfNewer);
        // 同步提交
        if(!coordinator.commitOffsetsSync(new HashMap < > (offsets), time.timer(timeout))) {
            throw new TimeoutException("Timeout of " + timeout.toMillis() + "ms expired before successfully " + "committing offsets " + offsets);
        }
    } finally {
        release();
    }
}
public boolean commitOffsetsSync(Map < TopicPartition, OffsetAndMetadata > offsets, Timer timer) {
    invokeCompletedOffsetCommitCallbacks();
    if(offsets.isEmpty()) return true;
    do {
        if(coordinatorUnknown() && !ensureCoordinatorReady(timer)) {
            return false;
        }
        // 发送提交请求
        RequestFuture < Void > future = sendOffsetCommitRequest(offsets);
        client.poll(future, timer);
        // We may have had in-flight offset commits when the 
        synchronous commit began.If so, ensure that
            // the corresponding callbacks are invoked prior to 
        returning in order to preserve the order that
            // the offset commits were applied.
        invokeCompletedOffsetCommitCallbacks();
        // 提交成功
        if(future.succeeded()) {
            if(interceptors != null) interceptors.onCommit(offsets);
            return true;
        }
        if(future.failed() && !future.isRetriable()) throw future.exception();
        timer.sleep(rebalanceConfig.retryBackoffMs);
    } while (timer.notExpired());
    return false;
}
```

#### 2. 手动异步提交 Offset

`CustomConsumer.java`

```java
// 手动提交
properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
// 1 创建一个消费者 "", "hello"
KafkaConsumer < String, String > kafkaConsumer = new
KafkaConsumer < > (properties);
// 2 订阅主题 first
ArrayList < String > topics = new ArrayList < > ();
topics.add("first");
kafkaConsumer.subscribe(topics);
// 3 消费数据
while(true) {
    ConsumerRecords < String, String > consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));
    for(ConsumerRecord < String, String > consumerRecord: consumerRecords) {
        System.out.println(consumerRecord);
    }
    // 手动提交 offset
    // kafkaConsumer.commitSync();
    kafkaConsumer.commitAsync();
}
```

`KafkaConsumer.java`

```java
@Override
public void commitAsync() {
    commitAsync(null);
}

@Override
public void commitAsync(OffsetCommitCallback callback) {
    commitAsync(subscriptions.allConsumed(), callback);
}

@Override
public void commitAsync(final Map < TopicPartition, OffsetAndMetadata > offsets, OffsetCommitCallback callback) {
    acquireAndEnsureOpen();
    try {
        maybeThrowInvalidGroupIdException();
        log.debug("Committing offsets: {}", offsets);
        offsets.forEach(this::updateLastSeenEpochIfNewer);
        // 提交 offset
        coordinator.commitOffsetsAsync(new HashMap < > (offsets), callback);
    } finally {
        release();
    }
}
public void commitOffsetsAsync(final Map < TopicPartition, OffsetAndMetadata > offsets, final OffsetCommitCallback callback) {
    invokeCompletedOffsetCommitCallbacks();
    if(!coordinatorUnknown()) {
        doCommitOffsetsAsync(offsets, callback);
    } else {
        // we don't know the current coordinator, so try to find it 
        and then send the commit
        // or fail (we don't want recursive retries which can cause 
        offset commits to arrive
        // out of order). Note that there may be multiple offset 
        commits chained to the same
        // coordinator lookup request. This is fine because the 
        listeners will be invoked in
            // the same order that they were added. Note also that 
            AbstractCoordinator prevents
            // multiple concurrent coordinator lookup requests.
        pendingAsyncCommits.incrementAndGet();
        // 监听提交 offset 的结果
        lookupCoordinator().addListener(new RequestFutureListener < Void > () {@
            Override
            public void onSuccess(Void value) {
                pendingAsyncCommits.decrementAndGet();
                doCommitOffsetsAsync(offsets, callback);
                client.pollNoWakeup();
            }@
            Override
            public void onFailure(RuntimeException e) {
                pendingAsyncCommits.decrementAndGet();
                completedOffsetCommits.add(new OffsetCommitCompletion(callback, offsets, new RetriableCommitFailedException(e)));
            }
        });
    }
    // ensure the commit has a chance to be transmitted (without blocking on its completion).
    // Note that commits are treated as heartbeats by the coordinator, so there is no need to
    // explicitly allow heartbeats through delayed task execution.
    client.pollNoWakeup();
}
```

## 4. 服务器源码

- broker 总体工作流程

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.xhieh88qlmo.jpg)

### 1. 程序入口

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/kafka/image.1cuz6mqtke2o.jpg)

`Kafka.scala`

```scala
def main(args: Array[String]): Unit = {
    try {
        // 获取参数相关信息
        val serverProps = getPropsFromArgs(args)
            // 配置服务
        val server = buildServer(serverProps)
        try {
            if(!OperatingSystem.IS_WINDOWS && !Java.isIbmJdk) new LoggingSignalHandler().register()
        } catch {
            case e:
                ReflectiveOperationException => warn("Failed to register optional signal handler that logs a 
                    message when the process is terminated " +
                    s "by a signal. Reason for registration failure is: $e", e)
        }
        // attach shutdown handler to catch terminating signals as well 
        as normal termination
        Exit.addShutdownHook("kafka-shutdown-hook", {
                try server.shutdown()
                catch {
                    case _:
                        Throwable => fatal("Halting Kafka.")
                            // Calling exit() can lead to deadlock as exit() can be 
                        called multiple times.Force exit.
                        Exit.halt(1)
                }
            })
            // 启动服务
        try server.startup()
        catch {
            case _:
                Throwable =>
                    // KafkaServer.startup() calls shutdown() in case of 
                    exceptions, so we invoke `exit`
                to set the status code
                fatal("Exiting Kafka.")
                Exit.exit(1)
        }
        server.awaitShutdown()
    } catch {
        case e:
            Throwable => fatal("Exiting Kafka due to fatal exception", e)
            Exit.exit(1)
    }
    Exit.exit(0)
}
```