---
title: 2. Kafka 安装与基本使用
date: 2022-05-02 00:00:00
permalink: /pages/ca2661/
categories:
  - 数据库
  - Kafka
tags:
  - 
author: 
  name: brook-w
  link: https://github.com/brook-w
---

## 1. 安装部署

### 1. Zookeeper 架构安装

#### 1. 集群规划

|hadoop102| hadoop103| hadoop104|
|---|---|---|
|zk |zk |zk|
|kafka| kafka| kafka|

#### 2. 集群部署

[下载地址](http://kafka.apache.org/downloads.html)

- 1. 解压安装包 

```sh
tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/
```

- 2. 修改文件夹 

```sh
mv kafka_2.12-3.0.0/ kafka
```

- 3. 进入到`/opt/module/kafka` 目录，修改配置文件 

```sh
cd config/ && vim server.properties

#broker 的全局唯一编号，不能重复，只能是数字。
broker.id=0
#处理网络请求的线程数量
num.network.threads=3
#用来处理磁盘 IO 的线程数量
num.io.threads=8
#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400
#接收套接字的缓冲区大小
socket.receive.buffer.bytes=102400
#请求套接字的缓冲区大小
socket.request.max.bytes=104857600
#kafka 运行日志(数据)存放的路径，路径不需要提前创建，kafka 自动帮你创建，可以
配置多个磁盘路径，路径与路径之间可以用"，"分隔
log.dirs=/opt/module/kafka/datas
#topic 在当前 broker 上的分区个数
num.partitions=1
#用来恢复和清理 data 下数据的线程数量
num.recovery.threads.per.data.dir=1
# 每个 topic 创建时的副本数，默认时 1 个副本
offsets.topic.replication.factor=1
#segment 文件保留的最长时间，超时将被删除
log.retention.hours=168
#每个 segment 文件的大小，默认最大 1G
log.segment.bytes=1073741824
# 检查过期数据的时间，默认 5 分钟检查一次是否数据过期
log.retention.check.interval.ms=300000
#配置连接 Zookeeper 集群地址（在 zk 根目录下创建/kafka，方便管理）
zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/ka
fka
```

- 4. 向其他主机分发包

```sh
xsync kafka/
```

- 5. 分别在 hadoop103 和 hadoop104 上修改配置文件`/opt/module/kafka/config/server.properties`  broker.id=1、broker.id=2
    :::danger 注意
    broker.id 不得重复，整个集群中唯一
    :::
- 6. 配置环境变量
  - 1. 在`/etc/profile.d/my_env.sh` 文件中增加 kafka 环境变量配置
    ```sh
    sudo vim /etc/profile.d/my_env.sh
    #KAFKA_HOME
    export KAFKA_HOME=/opt/module/kafka
    export PATH=$PATH:$KAFKA_HOME/bin
    ```
  - 2. 刷新环境变量
    ```sh
    source /etc/profile
    ```
  - 3. 分发环境变量文件到其他节点，并 source 
    ```sh
    xsync /etc/profile.d/my_env.sh
    ```
- 7. 启动集群

  - 1. 通过脚本启动 zk
    ```sh
    zk.sh start
    ```

  - 2. 依次在 hadoop102、hadoop103、hadoop104 节点上启动 Kafka
    ```sh
    bin/kafka-server-start.sh -daemon
    config/server.properties
    ```

- 8. 关闭集群(分别在三台机器上执行)
  ```sh
  bin/kafka-server-stop.sh
  ```

#### 3. 集群启停脚本

```sh
vi kf.sh

#! /bin/bash
case $1 in
"start"){
 for i in hadoop102 hadoop103 hadoop104
    do
      echo " --------启动 $i Kafka-------"
      ssh $i "/opt/module/kafka/bin/kafka-server-start.sh -
      daemon /opt/module/kafka/config/server.properties"
    done
};;

"stop"){
 for i in hadoop102 hadoop103 hadoop104
    do
      echo " --------停止 $i Kafka-------"
      ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh "
    done
};;
esac
```

- 赋权：`chmod +x kf.sh`
- 启动：` kf.sh start`
- 停止：` kf.sh stop`

:::danger 注意
停止 Kafka 集群时，一定要等 Kafka 所有节点进程全部停止后再停止Zookeeper
集群。因为 Zookeeper 集群当中记录着 Kafka 集群相关信息，Zookeeper 集群一旦先停止，Kafka 集群就没有办法再获取停止进程的信息，只能手动杀死 Kafka 进程了。
:::


### 2. Kafka-Kraft 架构安装

#### 1. Kafka-Kraft 架构

![image](https://cdn.staticaly.com/gh/brook-w/image-hosting@master/kafka/image.5a6plbkhlwc0.jpg)

左图为 Kafka 现有架构，元数据在 zookeeper 中，运行时动态选举 controller，由
controller 进行 Kafka 集群管理。右图为 kraft 模式架构（实验性），不再依赖 zookeeper 集群，而是用三台 controller 节点代替 zookeeper，元数据保存在 controller 中，由 controller 直接进行 Kafka 集群管理

这样做的好处有以下几个：

- Kafka 不再依赖外部框架，而是能够独立运行
- controller 管理集群时，不再需要从 zookeeper 中先读取数据，集群性能上升
- 由于不依赖 zookeeper，集群扩展时不再受到 zookeeper 读写能力限制
- controller 不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强
- controller 节点的配置，而不是像以前一样对随机 controller 节点的高负载束手无策

#### 2. Kafka-Kraft 集群部署

- 1. 解压一份 kafka 安装包 并移动目录
```sh
tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/
mv kafka_2.12-3.0.0/ kafka2
```

- 2. 在 hadoop102 上修改`/opt/module/kafka2/config/kraft/server.properties` 配置文件

```sh
vim server.properties

#kafka 的角色（controller 相当于主机、broker 节点相当于从机，主机类似 zk 功能）
process.roles=broker, controller
#节点 ID
node.id=2
#controller 服务协议别名
controller.listener.names=CONTROLLER
#全 Controller 列表
controller.quorum.voters=2@hadoop102:9093,3@hadoop103:9093,4@hado
op104:9093
#不同服务器绑定的端口
listeners=PLAINTEXT://:9092,CONTROLLER://:9093
#broker 服务协议别名
inter.broker.listener.name=PLAINTEXT
#broker 对外暴露的地址
advertised.Listeners=PLAINTEXT://hadoop102:9092
#协议别名到安全协议的映射
listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLA
INTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
#kafka 数据存储目录
log.dirs=/opt/module/kafka2/data
```

- 3. 分发 kafka2
  - 在 hadoop103 和 hadoop104 上 需 要 对 node.id 相应改变，值需要和controller.quorum.voters 对应
  - 在 hadoop103 和 hadoop104 上需要 根据各自的主机名称，修改相应的advertised.Listeners 地址

```sh
xsync kafka2/
```

- 4. 初始化集群数据目录
  - 1. 首先生成存储目录唯一 ID
    ```sh
    bin/kafka-storage.sh random-uuid

    J7s9e8PPTKOO47PxzI39VA
    ```
  - 2. 用该 ID 格式化 kafka 存储目录（三台节点）
    ```sh
    [atguigu@hadoop102 kafka2]$ bin/kafka-storage.sh format -t 
    J7s9e8PPTKOO47PxzI39VA -c 
    /opt/module/kafka2/config/kraft/server.properties

    [atguigu@hadoop103 kafka2]$ bin/kafka-storage.sh format -t 
    J7s9e8PPTKOO47PxzI39VA -c 
    /opt/module/kafka2/config/kraft/server.properties

    [atguigu@hadoop104 kafka2]$ bin/kafka-storage.sh format -t 
    J7s9e8PPTKOO47PxzI39VA -c 
    /opt/module/kafka2/config/kraft/server.properties
    ```

- 5. 启动 kafka 集群
  ```sh
  [atguigu@hadoop102 kafka2]$ bin/kafka-server-start.sh -daemon 
  config/kraft/server.properties
  
  [atguigu@hadoop103 kafka2]$ bin/kafka-server-start.sh -daemon 
  config/kraft/server.properties

  [atguigu@hadoop104 kafka2]$ bin/kafka-server-start.sh -daemon 
  config/kraft/server.properties
  ```

- 6. 停止 kafka 集群

```sh
[atguigu@hadoop102 kafka2]$ bin/kafka-server-stop.sh
[atguigu@hadoop103 kafka2]$ bin/kafka-server-stop.sh
[atguigu@hadoop104 kafka2]$ bin/kafka-server-stop.sh
```

#### 3. Kafka-Kraft 集群启动停止脚本



```sh
vim kf2.sh

# 脚本内容
#! /bin/bash
case $1 in
"start"){
  for i in hadoop102 hadoop103 hadoop104
  do
      echo " --------启动 $i Kafka2-------"
      ssh $i "/opt/module/kafka2/bin/kafka-server-start.sh -daemon /opt/module/kafka2/config/kraft/server.properties"
  done
};;
"stop"){
  for i in hadoop102 hadoop103 hadoop104
  do
      echo " --------停止 $i Kafka2-------"
      ssh $i "/opt/module/kafka2/bin/kafka-server-stop.sh"
  done
};;
esac

# 赋权
chmod +x kf2.sh

# 启动节点
kf2.sh start

# 关闭节点
kf2.sh stop
```


## 2. Kafka 命令行操作

![image](https://cdn.staticaly.com/gh/brook-w/image-hosting@master/kafka/image.357qj0aqhp80.jpg)


### 1. 主题命令行操作

- 1. 查看操作主题命令参数

```
bin/kafka-topics.sh
```

|参数| 描述|
|---|---|
|--bootstrap-server <String: server toconnect to>| 连接的 Kafka Broker 主机名称和端口号|
|--topic <String: topic> |操作的 topic 名称|
|--create |创建主题|
|--delete| 删除主题|
|--alter| 修改主题|
|--list |查看所有主题|
|--describe| 查看主题详细描述|
|--partitions <Integer: # of partitions>| 设置分区数|
|--replication-factor<Integer: replication factor> |设置分区副本|
|--config <String: name=value> |更新系统默认的配置|

- 2. 查看当前服务器中的所有 topic

```sh 
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --list
```

- 3. 创建 first topic
  - --topic 定义 topic 名
  - --replication-factor 定义副本数
  - --partitions 定义分区数

```sh
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --partitions 1 --replication-factor 3 -- topic first
```

- 4. 查看 first 主题的详情

```sh
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic first
```

- 5. 修改分区数（***注意：分区数只能增加，不能减少***）

```sh
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --alter --topic first --partitions 3
 ```
- 6. 删除 topic

```sh
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --delete --topic first
```

### 2. 生产者命令行操作
- 1. 查看操作生产者命令参数

```sh
bin/kafka-console-producer.sh
```

|参数| 描述|
|---|---|
|--bootstrap-server <String: server toconnect to> |连接的 Kafka Broker 主机名称和端口号|
|--topic <String: topic> |操作的 topic 名称|

- 2. 发送消息

```sh
bin/kafka-console-producer.sh --bootstrap-server hadoop102:9092 --topic first
>hello
>world
```

### 3. 消费者命令行操作

- 1. 查看操作消费者命令参数

```sh
bin/kafka-console-consumer.sh
```

|参数| 描述|
|---|---|
|--bootstrap-server <String: server toconnect to> |连接的 Kafka Broker 主机名称和端口号|
|--topic <String: topic> |操作的 topic 名称|
|--from-beginning |从头开始消费|
|--group <String: consumer group id>| 指定消费者组名称|

- 2. 消费消息

  - 1. 消费 first 主题中的数据
  ```sh
  bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first
  ```

  - 2. 把主题中所有的数据都读取出来
  ```sh
  bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning --topic first
  ```