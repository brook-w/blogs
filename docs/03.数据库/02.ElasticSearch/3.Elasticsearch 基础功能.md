---
title: 3. Elasticsearch 基础功能
date: 2022-02-03 00:00:00
permalink: /pages/04eb04/
categories:
  - 技术
  - ElasticSearch
tags:
  - 
author: 
  name: brook-w
  link: https://github.com/brook-w
---

## 1. 索引操作
### 1. 创建索引

ES 的索引类比 Mysql 中表的概念创建一个索引，类似于创建一个表。查询完成后，Kibana 右侧会返回响应结果及请求状态

```sh
PUT myindex # Kibana
http://127.0.0.1:9200/myindex [PUT]
```
```json
{
 "acknowledged"【响应结果】: true, # true 操作成功
 "shards_acknowledged"【分片结果】: true, # 分片操作成功
 "index"【索引名称】: "myindex"
}

```

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.3izb0ucpb020.jpg)

重复创建索引时，会出现报错信息

### 2. 查询指定索引
```sh
GET myindex
http://127.0.0.1:9200/myindex [GET]
```

### 3.查询所有索引
```sh
GET _cat/indices
http://127.0.0.1:9200/_cat/indices?v
```
![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.5w1tyfstdrs0.jpg)

这里的查询结果表示索引的状态信息，按顺序数据表示结果如下：

| 内容                   | 含义           | 具体描述                                                                          |
| ---------------------- | -------------- | --------------------------------------------------------------------------------- |
| green                  | health         | 当前服务器健康状态： green(集群完整) yellow(单点正常、集群不完整) red(单点不正常) |
| open                   | status         | 索引打开关闭状态                                                                  |
| myindex                | index          | 索引名称                                                                          |
| Swx2xWHLR6yv23kTrK3sAg | uuid           | 索引统一编号                                                                      |
| 1                      | pri            | 主分片数量                                                                        |
| 1                      | rep            | 副本数量                                                                          |
| 0                      | docs.count     | 可用文档数量                                                                      |
| 0                      | docs.deleted   | 文档删除状态                                                                      |
| 450b                   | store.size     | 主分片和副本分片占整体空间的大小                                                  |
| 225b                   | pri.store.size | 主分片占空间大小                                                                  |

### 4. 删除索引
![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.4krah6e9kaw0.jpg)

如果删除一个不存在的索引，那么会返回错误信息

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.26vf7zujjtno.jpg)

## 2. 文档操作

文档是 ES 搜索数据的最小单位，不依赖预先定义的模式，所以可以将文档类比为表的一行 JSON 类型的数据。再 ES 中不再像传统数据库中那样定义字段，可以灵活的添加和删减字段
### 1. 创建文档

在创建好索引的前提下，创建文档，并添加数据。这里的文档可以类比为关系数据库中的表数据，添加的数据格式为 `json`

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.5kxrtnh5cpw0.jpg)

> 此处因为没有指定数据唯一性标识，所以无法使用 PUT 请求，只能使用 POST 请求，且对
数据会生成随机的唯一性标识。否则会返回错误信息

如果在创建数据时，指定唯一性标识，那么请求范式 POST，PUT 都可以

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.5sdas95ws8s0.jpg)

### 2. 查询文档

根据唯一性标识可以查询对应的文档

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.4u1vdqw87ou0.jpg)

### 3. 修改文档

修改文档本质上和新增文档是一样的，如果存在就修改，如果不存在就新增

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.1yaxnwjkeqbk.jpg)

### 4. 删除文档

删除一个文档不会立即从磁盘上移除，它只是被标记成已删除`（逻辑删除）`

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.4u9jv9y5a0a0.jpg)

### 5. 查询所有文档
![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.2r5tu5ed0aw0.jpg)

## 3. 数据搜索

准备数据

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.19m75wz0n7z4.jpg)

### 1. 查询所有文档

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.1tuxipln34w0.jpg)

### 2. 匹配查询文档
这里的查询表示文档数据中 JSON 对象数据中的 name 属性是 zhangsan。

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.35dn7jqp8ns0.jpg)

### 3. 匹配查询字段

默认情况下，Elasticsearch 在搜索的结果中，会把文档中保存在_source 的所有字段都返回。
如果我们只想获取其中的部分字段，我们可以添加_source 的过滤

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.56nhu0pw9x00.jpg)


## 4. 聚合搜索

聚合允许使用者对 es 文档进行统计分析，类似与关系型数据库中的 group by，当然还有很
多其他的聚合，例如取最大值、平均值等等

### 1. 平均值

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.47969ti1pue0.jpg)

### 2. 求和

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.2rznvs6kxy80.jpg)

### 3. 最大值

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.4ovocgtm9g20.jpg)

### 4. TopN

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.7edti5yn8880.jpg)


## 5. 索引模板

我们之前对索引进行一些配置信息设置，但是都是在单个索引上进行设置。在实际开发
中，我们可能需要创建不止一个索引，但是每个索引或多或少都有一些共性。比如我们在设
计关系型数据库时，一般都会为每个表结构设计一些常用的字段，比如：创建时间，更新时
间，备注信息等。elasticsearch 在创建索引的时候，就引入了模板的概念，你可以先设置一
些通用的模板，在创建索引的时候，elasticsearch 会先根据你创建的模板对索引进行设置

elasticsearch 中提供了很多的默认设置模板，这就是为什么我们在新建文档的时候，可以为
你自动设置一些信息，做一些字段转换等。

索引可使用预定义的模板进行创建,这个模板称作 Index templates。模板设置包括 settings
和 mappings

### 1. 创建模板

```json
# 模板名称小写
PUT _template/mytemplate
{
 "index_patterns" : [
    "my*"
 ],
 "settings" : {
    "index" : {
        "number_of_shards" : "1"
    }
 },
 "mappings" : {
    "properties" : {
        "now": {
            "type" : "date",
            "format" : "yyyy/MM/dd"
            }
        }
    } 
 }
 ```

 ![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.5ia9gkzsf8s0.jpg)


### 2. 查看模板

```
GET /_template/mytemplate
```

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.2q7ka3gwah20.jpg)

### 3. 验证模板是否存在

```
HEAD /_template/mytemplate
```

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.5gcufzpe2no0.jpg)

### 4. 创建索引

```
PUT mytest # my* 命中
```

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.4w1gdqsevy00.jpg)

### 5. 删除模板

```
DELETE /_template/mytemplate
```

## 6. 中文分词

我们在使用 Elasticsearch 官方默认的分词插件时会发现，其对中文的分词效果不佳，经
常分词后得效果不是我们想要的

为了能够更好地对中文进行搜索和查询，就需要在Elasticsearch中集成好的分词器插件，
而 IK 分词器就是用于对中文提供支持得插件

### 1. 集成 IK 分词器

下载地址：[https://github.com/medcl/elasticsearch-analysis-ik/releases](https://github.com/medcl/elasticsearch-analysis-ik/releases)

::: tip
注意：选择下载的版本要与 Elasticsearch 版本对应。我们这里选择 8.1.0
:::

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.6gwis4ac1oo0.jpg)

### 2. 安装
在安装目录的 plugins 目中，将下载得压缩包直接解压缩得里面即可

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.4ft2k96ql560.jpg)

::: warning 注意
重启 Elasticsearch 服务
:::

### 3. 使用 IK 分词器

> IK 分词器提供了两个分词算法：
> 
> 1. ik_smart: 最少切分
> 2. Ik_max_word:最细粒度划分

接下来咱们使用 ik_smart 算法对之前得中文内容进行分词

```json
GET _analyze
{
 "analyzer": "ik_smart",
 "text": ["我是一个学生"]
}
```
![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.4wey083mqns0.jpg)

接下来，再对比 ik_max_word 算法分词后的效果
![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.6dtqzlmuka80.jpg)

### 4. 自定义分词效果

我们在使用 IK 分词器时会发现其实有时候分词的效果也并不是我们所期待的,有时一些特
殊得术语会被拆开，比如上面得中文“一个学生”希望不要拆开，怎么做呢？其实 IK 插件
给我们提供了自定义分词字典，我们就可以添加自己想要保留得字了

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.50safyr7ef80.jpg)

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.1ev5g99q63mo.jpg)

接下来我们修改配置文件：`IKAnalyzer.cfg.xml`

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
    <comment>IK Analyzer 扩展配置</comment>
    <!--用户可以在这里配置自己的扩展字典 -->
    <entry key="ext_dict">test.dic</entry>
    <!--用户可以在这里配置自己的扩展停止词字典-->
    <entry key="ext_stopwords"></entry>
    <!--用户可以在这里配置远程扩展字典 -->
    <!-- <entry key="remote_ext_dict">words_location</entry> -->
    <!--用户可以在这里配置远程扩展停止词字典-->
    <!-- <entry key="remote_ext_stopwords">words_location</entry> -->
</properties>
```

:::warning 提示
重启 Elasticsearch 服务器查看效果
:::

```json
GET _analyze
{
 "analyzer": "ik_smart",
 "text": ["我是一个学生"]
}
```
![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.n41c6sjyybk.jpg)

## 7. 文档得分

Lucene 和 ES 的得分机制是一个基于词频和逆文档词频的公式，简称为 TF-IDF 公式

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.1whniwlaqnwg.jpg)

公式中将查询作为输入，使用不同的手段来确定每一篇文档的得分，将每一个因素最后
通过公式综合起来，返回该文档的最终得分。这个综合考量的过程，就是我们希望相关的文
档被优先返回的考量过程。在 Lucene 和 ES 中这种相关性称为得分

考虑到查询内容和文档得关系比较复杂，所以公式中需要输入得参数和条件非常得多。但是其中比较重要得其实是两个算法机制

::: tip .
 
> TF (词频)
>
>  - Term Frequency : 搜索文本中的各个词条（term）在查询文本中出现了多少次,出现次数越多，就越相关，得分会比较高


> IDF(逆文档频率)
>
>  - Term Frequency : Inverse Document Frequency : 搜索文本中的各个词条（term）在整个索引的所有文档中
出现了多少次，出现的次数越多，说明越不重要，也就越不相关，得分就比较低

:::

### 1. 打分机制

接下来咱们用一个例子简单分析一下文档的打分机制：

1. 首先，咱们先准备一个基础数据
```json
# 创建索引
PUT /atguigu
# 增加文档数据
# 此时索引中只有这一条数据
PUT /atguigu/_doc/1
{
 "text":"hello"
}
```

2. 查询匹配条件的文档数据
```json
GET /atguigu/_search
{
  "query": {
    "match": {
      "text": "hello"
    }
  }
}
 ```

 ![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.7agfb5451f00.jpg)

 这里文档的得分为：`0.2876821` 很低？一起分析一下

 3. 分析文档数据打分过程

 ```json
 # 增加分析参数
GET /atguigu/_search?explain=true 
{
  "query": {
    "match": {
      "text": "hello"
    }
  }
}
 ```

 执行后，会发现打分机制中有 2 个重要阶段：计算 TF 值和 IDF 值

 ![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.28zfqeyx9jwg.jpg)

 ![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.2a85126dxzwg.jpg)

 最后的分数为：

 ![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.31450kp0z2a0.jpg)

 4. 计算 TF 值

 ![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.s4teyfo1q8g.jpg)


| 参数                      | 含义                                             | 取值           |
| ------------------------- | ------------------------------------------------ | -------------- |
| freq 文档中出现词条的次数 | 1.0                                              |
| k1                        | 术语饱和参数                                     | 1.2（默认值）  |
| b                         | 长度规格化参数（单词长度对于整个文档的影响程度） | 0.75（默认值） |
| dl                        | 当前文中分解的字段长度                           | 1.0            |
| avgdl                     | 查询文档中分解字段数量/查询文档数量              | 1.0            |
| TF（词频）                | 1.0/(1 + 1.2 * (1 - 0.75 + 0.75*1.0/1.0))        | 0.454545       |

5. 计算 IDF 值

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.59yfu46tsng0.jpg)

| 参数              | 含义                                         | 取值      |
| ----------------- | -------------------------------------------- | --------- |
| N                 | 包含查询字段的文档总数（不一定包含查询词条） | 1         |
| n                 | 包含查询词条的文档数                         | 1         |
| IDF（逆文档频率） | log(1 + (1 - 1 + 0.5) / (1 + 0.5))           | 0.2876821 |

**这里的 log 是底数为 e 的对数**

7. 增加新的文档，测试得分

-  增加一个毫无关系的文档
```json
# 增加文档
PUT /atguigu/_doc/2
{
 "text" : "spark"
}
# 因为新文档无词条相关信息，所以匹配的文档数据得分就应该较高：
# 0.6931741
GET /atguigu/_search
{
  "query": {
    "match": {
        "text": "hello"
      }
    } 
 }
 ```

 ![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.28phpvdivvi8.jpg)

- 增加一个一模一样的文档

```json
# 增加文档
PUT /atguigu/_doc/2
{
 "text" : "hello"
}
# 因为新文档含词条相关信息，且多个文件含有词条，所以显得不是很重要，得分会变低
# 0.18232156
GET /atguigu/_search
{
  "query": {
    "match": {
      "text": "hello"
    }
  } 
 }
 ```

 ![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.1nxr8gzjmc00.jpg)

 - 增加一个含有词条，但是内容较多的文档

 ```json
 # 增加文档
PUT /atguigu/_doc/2
{
 "text" : "hello elasticsearch" }
# 因为新文档含词条相关信息，但只是其中一部分，所以查询文档的分数会变得更低一些。
# 0.14874382
GET /atguigu/_search
{
 "query": {
    "match": {
      "text": "hello"
    }
  } 
}
 ```
 ![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.78jzqn6x2i00.jpg)

 ### 2. 案例

需求：
> 查询文档标题中含有“Hadoop”,“Elasticsearch”,“Spark”的内容。
优先选择“Spark”的内容

1. 准备数据
```json
# 准备数据
PUT /testscore/_doc/1001
{
 "title" : "Hadoop is a Framework",
 "content" : "Hadoop 是一个大数据基础框架" 
}
PUT /testscore/_doc/1002
{
 "title" : "Hive is a SQL Tools",
 "content" : "Hive 是一个 SQL 工具" 
}
PUT /testscore/_doc/1003
{
 "title" : "Spark is a Framework",
 "content" : "Spark 是一个分布式计算引擎" 
}
 ```

2. 查询数据

```json
# 查询文档标题中含有“Hadoop”,“Elasticsearch”,“Spark”的内容
GET /testscore/_search?explain=true
{
    "query":{
        "bool":{
            "should":[
                {
                    "match":{
                        "title":{
                            "query":"Hadoop",
                            "boost":1
                        }
                    }
                },
                {
                    "match":{
                        "title":{
                            "query":"Hive",
                            "boost":1
                        }
                    }
                },
                {
                    "match":{
                        "title":{
                            "query":"Spark",
                            "boost":1
                        }
                    }
                }
            ]
        }
    }
}
```

此时，你会发现，Spark 的结果并不会放置在最前面

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.3lrcfy01gh20.jpg)

此时，咱们可以更改 Spark 查询的权重参数 boost.看看查询的结果有什么不同

```json
# 查询文档标题中含有“Hadoop”,“Elasticsearch”,“Spark”的内容
GET /testscore/_search?explain=true
{
    "query":{
        "bool":{
            "should":[
                {
                    "match":{
                        "title":{
                            "query":"Hadoop",
                            "boost":1
                        }
                    }
                },
                {
                    "match":{
                        "title":{
                            "query":"Hive",
                            "boost":1
                        }
                    }
                },
                {
                    "match":{
                        "title":{
                            "query":"Spark",
                            "boost":2
                        }
                    }
                }
            ]
        }
    }
}
```

![image](https://cdn.jsdelivr.net/gh/brook-w/image-hosting@master/es/image.6v8h141px600.jpg)